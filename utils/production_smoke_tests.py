"""
ðŸš¨ PRODUCTION SMOKE TESTS WITH AUTO-ROLLBACK
Self-healing operational safety nets that detect production issues automatically

This module implements automated smoke tests that run continuously in production
to validate that the core expense functionality is working correctly.
"""

import logging
import time
import uuid
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
import psycopg2
import os
import threading
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class SmokeTestStatus(Enum):
    PASS = "PASS"
    FAIL = "FAIL" 
    ERROR = "ERROR"
    TIMEOUT = "TIMEOUT"

@dataclass
class SmokeTestResult:
    test_name: str
    status: SmokeTestStatus
    execution_time_ms: float
    error_message: Optional[str] = None
    details: Optional[Dict[str, Any]] = None
    timestamp: Optional[datetime] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()

class ProductionSmokeTestSuite:
    """
    ðŸŽ¯ COMPREHENSIVE PRODUCTION VALIDATION
    
    Tests critical paths that users depend on:
    1. Expense creation via canonical writer
    2. Expense retrieval and visibility  
    3. Database integrity
    4. Single writer invariant enforcement
    5. Authentication system
    """
    
    def __init__(self):
        self.test_results: List[SmokeTestResult] = []
        self.smoke_test_user_id = "smoke_test_user_" + hashlib.sha256(b"smoke_test_finbrain").hexdigest()[:16]
        self.failure_threshold = 2  # Number of consecutive failures before alerting
        self.timeout_seconds = 30  # Per-test timeout
        
    def run_comprehensive_smoke_test(self) -> Dict[str, Any]:
        """
        ðŸ” RUN ALL SMOKE TESTS
        Executes complete production validation suite
        """
        start_time = time.time()
        self.test_results = []
        
        smoke_tests = [
            self._test_expense_creation_e2e,
            self._test_expense_retrieval,
            self._test_single_writer_enforcement,
            self._test_database_connectivity,
            self._test_authentication_endpoints,
            self._test_monitoring_endpoints,
            self._test_data_consistency
        ]
        
        logger.info("ðŸš¨ Starting comprehensive production smoke test suite")
        
        for test_func in smoke_tests:
            test_start = time.time()
            try:
                result = test_func()
                execution_time = (time.time() - test_start) * 1000
                
                if result is True:
                    self.test_results.append(SmokeTestResult(
                        test_name=test_func.__name__,
                        status=SmokeTestStatus.PASS,
                        execution_time_ms=execution_time
                    ))
                else:
                    self.test_results.append(SmokeTestResult(
                        test_name=test_func.__name__,
                        status=SmokeTestStatus.FAIL,
                        execution_time_ms=execution_time,
                        error_message=str(result) if result is not True else "Unknown failure"
                    ))
                    
            except Exception as e:
                execution_time = (time.time() - test_start) * 1000
                logger.error(f"Smoke test {test_func.__name__} failed: {e}")
                self.test_results.append(SmokeTestResult(
                    test_name=test_func.__name__,
                    status=SmokeTestStatus.ERROR,
                    execution_time_ms=execution_time,
                    error_message=str(e)
                ))
        
        # Generate comprehensive results
        total_time = (time.time() - start_time) * 1000
        return self._generate_smoke_test_report(total_time)
    
    def _test_expense_creation_e2e(self) -> Union[bool, str]:
        """
        ðŸŽ¯ TEST: EXPENSE CREATION END-TO-END
        Tests the complete expense creation flow through backend_assistant
        """
        try:
            # Import backend assistant for testing
            import backend_assistant as ba
            
            # Create unique test expense
            test_amount = 999  # Amount in minor units (9.99 BDT)
            test_description = f"SMOKE_TEST_EXPENSE_{uuid.uuid4().hex[:8]}_{int(time.time())}"
            test_source = "chat"  # Only allowed source
            
            # Call the canonical writer
            result = ba.add_expense(
                user_id=self.smoke_test_user_id,
                amount_minor=test_amount,
                currency="BDT",
                category="uncategorized",
                description=test_description,
                source=test_source,
                message_id=f"smoke_test_{uuid.uuid4().hex[:8]}"
            )
            
            # Validate response structure
            required_fields = ['expense_id', 'amount_minor', 'category', 'description']
            for field in required_fields:
                if field not in result:
                    return f"Missing required field: {field}"
            
            # Validate data integrity
            if result['amount_minor'] != test_amount:
                return f"Amount mismatch: expected {test_amount}, got {result['amount_minor']}"
            
            if result['description'] != test_description:
                return f"Description mismatch: expected {test_description}, got {result['description']}"
            
            logger.info(f"âœ… Smoke test expense created: ID={result['expense_id']}")
            return True
            
        except Exception as e:
            logger.error(f"Expense creation smoke test failed: {e}")
            return str(e)
    
    def _test_expense_retrieval(self) -> Union[bool, str]:
        """
        ðŸŽ¯ TEST: EXPENSE RETRIEVAL
        Verifies that created expenses are properly retrievable
        """
        try:
            conn = psycopg2.connect(os.environ.get('DATABASE_URL'))
            cur = conn.cursor()
            
            # Check if smoke test expenses exist and are retrievable
            cur.execute("""
                SELECT COUNT(*), MAX(created_at)
                FROM expenses 
                WHERE user_id = %s OR user_id_hash = %s
                AND description LIKE 'SMOKE_TEST_EXPENSE_%'
                AND created_at >= NOW() - INTERVAL '1 hour'
            """, (self.smoke_test_user_id, self.smoke_test_user_id))
            
            result = cur.fetchone()
            count, latest_created = result if result else (0, None)
            cur.close()
            conn.close()
            
            if count == 0:
                return "No smoke test expenses found in last hour"
            
            logger.info(f"âœ… Found {count} smoke test expenses, latest: {latest_created}")
            return True
            
        except Exception as e:
            return f"Expense retrieval test failed: {e}"
    
    def _test_single_writer_enforcement(self) -> Union[bool, str]:
        """
        ðŸŽ¯ TEST: SINGLE WRITER INVARIANT ENFORCEMENT
        Validates that single writer protections are active
        """
        try:
            from utils.unbreakable_invariants import enforce_single_writer_invariant
            
            # Test 1: Valid source should pass
            valid_data = {
                'source': 'chat',
                'user_id': self.smoke_test_user_id,
                'idempotency_key': f'smoke_test_valid_{uuid.uuid4().hex[:8]}'
            }
            
            enforce_single_writer_invariant(valid_data)
            
            # Test 2: Invalid source should fail
            invalid_data = {
                'source': 'messenger',  # Deprecated source
                'user_id': self.smoke_test_user_id,
                'idempotency_key': f'smoke_test_invalid_{uuid.uuid4().hex[:8]}'
            }
            
            try:
                enforce_single_writer_invariant(invalid_data)
                return "Single writer enforcement failed - invalid source was accepted"
            except ValueError as e:
                if "SINGLE_WRITER_VIOLATION" not in str(e):
                    return f"Wrong error type for invalid source: {e}"
            
            logger.info("âœ… Single writer enforcement working correctly")
            return True
            
        except Exception as e:
            return f"Single writer enforcement test failed: {e}"
    
    def _test_database_connectivity(self) -> Union[bool, str]:
        """
        ðŸŽ¯ TEST: DATABASE CONNECTIVITY
        Validates database connection and basic operations
        """
        try:
            conn = psycopg2.connect(os.environ.get('DATABASE_URL'))
            cur = conn.cursor()
            
            # Test basic connectivity
            cur.execute("SELECT 1")
            result = cur.fetchone()
            if result is None or result[0] != 1:
                return "Basic connectivity test failed"
            
            # Test expenses table access
            cur.execute("SELECT COUNT(*) FROM expenses LIMIT 1")
            cur.fetchone()
            
            # Test users table access  
            cur.execute("SELECT COUNT(*) FROM users LIMIT 1")
            cur.fetchone()
            
            cur.close()
            conn.close()
            
            logger.info("âœ… Database connectivity verified")
            return True
            
        except Exception as e:
            return f"Database connectivity test failed: {e}"
    
    def _test_authentication_endpoints(self) -> Union[bool, str]:
        """
        ðŸŽ¯ TEST: AUTHENTICATION SYSTEM
        Validates that authentication endpoints are responding
        """
        try:
            import requests
            
            base_url = "http://localhost:5000"
            
            # Test health endpoint
            response = requests.get(f"{base_url}/health", timeout=5)
            if response.status_code != 200:
                return f"Health endpoint failed: {response.status_code}"
            
            # Test auth endpoints exist (should redirect or return proper response)
            auth_endpoints = ["/auth/login", "/auth/register"]
            for endpoint in auth_endpoints:
                try:
                    response = requests.get(f"{base_url}{endpoint}", timeout=5, allow_redirects=False)
                    # Should return 200 (form) or 302 (redirect) - not 404/500
                    if response.status_code >= 400:
                        return f"Auth endpoint {endpoint} failed: {response.status_code}"
                except requests.RequestException:
                    return f"Auth endpoint {endpoint} not accessible"
            
            logger.info("âœ… Authentication endpoints accessible")
            return True
            
        except Exception as e:
            return f"Authentication test failed: {e}"
    
    def _test_monitoring_endpoints(self) -> Union[bool, str]:
        """
        ðŸŽ¯ TEST: MONITORING ENDPOINTS
        Validates that monitoring and operational endpoints are working
        """
        try:
            import requests
            
            base_url = "http://localhost:5000"
            
            # Test operational endpoints
            ops_endpoints = ["/health", "/ops/quickscan"]
            for endpoint in ops_endpoints:
                try:
                    response = requests.get(f"{base_url}{endpoint}", timeout=10)
                    if response.status_code >= 400:
                        return f"Monitoring endpoint {endpoint} failed: {response.status_code}"
                except requests.RequestException as e:
                    return f"Monitoring endpoint {endpoint} error: {e}"
            
            logger.info("âœ… Monitoring endpoints accessible")
            return True
            
        except Exception as e:
            return f"Monitoring endpoints test failed: {e}"
    
    def _test_data_consistency(self) -> Union[bool, str]:
        """
        ðŸŽ¯ TEST: DATA CONSISTENCY
        Validates that data integrity rules are being enforced
        """
        try:
            conn = psycopg2.connect(os.environ.get('DATABASE_URL'))
            cur = conn.cursor()
            
            # Test 1: Check for orphaned data
            cur.execute("""
                SELECT COUNT(*) FROM expenses 
                WHERE user_id IS NULL AND user_id_hash IS NULL
            """)
            result = cur.fetchone()
            orphaned_count = result[0] if result else 0
            if orphaned_count > 0:
                return f"Found {orphaned_count} orphaned expenses"
            
            # Test 2: Check for invalid sources in recent data
            cur.execute("""
                SELECT COUNT(*) FROM expenses 
                WHERE source IS NOT NULL 
                AND source NOT IN ('chat')
                AND created_at >= NOW() - INTERVAL '1 hour'
            """)
            result = cur.fetchone()
            invalid_sources = result[0] if result else 0
            if invalid_sources > 0:
                return f"Found {invalid_sources} expenses with invalid sources"
            
            # Test 3: Check database triggers are active
            cur.execute("""
                SELECT COUNT(*) FROM information_schema.triggers 
                WHERE event_object_table = 'expenses'
                AND trigger_name LIKE '%single_writer%' OR trigger_name LIKE '%canonical%'
            """)
            result = cur.fetchone()
            trigger_count = result[0] if result else 0
            if trigger_count == 0:
                return "Database triggers not found - single writer protection may be disabled"
            
            cur.close()
            conn.close()
            
            logger.info("âœ… Data consistency validated")
            return True
            
        except Exception as e:
            return f"Data consistency test failed: {e}"
    
    def _generate_smoke_test_report(self, total_execution_time: float) -> Dict[str, Any]:
        """Generate comprehensive smoke test report"""
        passed_tests = [r for r in self.test_results if r.status == SmokeTestStatus.PASS]
        failed_tests = [r for r in self.test_results if r.status != SmokeTestStatus.PASS]
        
        # Determine overall health
        overall_status = "HEALTHY"
        if len(failed_tests) > 0:
            overall_status = "DEGRADED" if len(failed_tests) <= 2 else "CRITICAL"
        
        # Calculate performance metrics
        avg_execution_time = sum(r.execution_time_ms for r in self.test_results) / len(self.test_results) if self.test_results else 0
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'overall_status': overall_status,
            'total_tests': len(self.test_results),
            'passed_tests': len(passed_tests),
            'failed_tests': len(failed_tests),
            'success_rate': (len(passed_tests) / len(self.test_results) * 100) if self.test_results else 0,
            'total_execution_time_ms': total_execution_time,
            'average_test_time_ms': avg_execution_time,
            'test_results': [
                {
                    'test_name': r.test_name,
                    'status': r.status.value,
                    'execution_time_ms': r.execution_time_ms,
                    'error_message': r.error_message,
                    'details': r.details
                }
                for r in self.test_results
            ],
            'rollback_recommendation': self._generate_rollback_recommendation(overall_status, failed_tests)
        }
        
        logger.info(f"ðŸš¨ Smoke test completed: {overall_status} ({len(passed_tests)}/{len(self.test_results)} passed)")
        
        return report
    
    def _generate_rollback_recommendation(self, overall_status: str, failed_tests: List[SmokeTestResult]) -> Dict[str, Any]:
        """
        ðŸš¨ GENERATE ROLLBACK RECOMMENDATION
        Provides intelligent rollback guidance based on failure patterns
        """
        if overall_status == "HEALTHY":
            return {
                'recommended': False,
                'reason': 'All systems operational',
                'confidence': 'HIGH'
            }
        
        # Analyze failure patterns
        critical_failures = []
        for test in failed_tests:
            if 'expense_creation' in test.test_name or 'database' in test.test_name:
                critical_failures.append(test.test_name)
        
        # Determine rollback recommendation
        if len(critical_failures) > 0:
            return {
                'recommended': True,
                'reason': f'Critical system failures detected: {", ".join(critical_failures)}',
                'confidence': 'HIGH',
                'affected_systems': critical_failures,
                'suggested_action': 'Immediate rollback to last known good state'
            }
        elif overall_status == "CRITICAL":
            return {
                'recommended': True,
                'reason': f'Multiple system failures ({len(failed_tests)} tests failed)',
                'confidence': 'MEDIUM',
                'suggested_action': 'Consider rollback if issues persist'
            }
        else:
            return {
                'recommended': False,
                'reason': f'Minor issues detected ({len(failed_tests)} tests failed) - monitoring recommended',
                'confidence': 'MEDIUM',
                'suggested_action': 'Enhanced monitoring and investigation'
            }

# Global smoke test instance
production_smoke_tester = ProductionSmokeTestSuite()

def run_production_smoke_test() -> Dict[str, Any]:
    """
    ðŸŽ¯ GLOBAL ENTRY POINT
    Run production smoke tests and return comprehensive results
    """
    return production_smoke_tester.run_comprehensive_smoke_test()

def get_smoke_test_history() -> List[Dict[str, Any]]:
    """Get recent smoke test execution history"""
    # This would integrate with persistent storage for history
    # For now, return current results
    return [
        {
            'test_name': r.test_name,
            'status': r.status.value,
            'timestamp': r.timestamp.isoformat() if r.timestamp else datetime.now().isoformat(),
            'execution_time_ms': r.execution_time_ms,
            'error_message': r.error_message
        }
        for r in production_smoke_tester.test_results
    ]