You are performing a read-only technical audit of this Replit project. Do not modify, move, install, upgrade, or delete anything. Do not run migrations or write to the database. Your job is to analyze and document.

Objectives
Understand the project architecture, runtime, and integrations.

Identify risks, misconfigurations, and likely failure points.

Produce a single audit document in the project root named:

Replit_Audit_Summary.md (primary, human-readable)

and also export a .docx version named Replit_Audit_Summary.docx with the same content.

Scope (read-only)
Files, folders, configs, env usage, processes, endpoints, webhooks, background jobs, queues, schedulers, databases, third-party services, and feature flags.

Messenger/WhatsApp webhook flows if present.

Any “Make/Zapier/n8n” hooks or placeholders if present.

Deliverables (document structure to fill)
Create the document with the following exact headings and fill them thoroughly from the repository’s actual state:

1. Project Snapshot
Project name

Primary language(s) and framework(s)

Entrypoint(s) and start commands

Runtime assumptions (Python/Node versions, Gunicorn/UVicorn/etc.)

Current Replit run configuration (if any)

2. File & Folder Map
Collapsed tree of the repo (include all top-level folders; list up to ~200 items; summarize if larger)

Note critical files: server entry, webhook handlers, workers, schedulers, env loaders, Dockerfile/Procfile, Makefiles, .replit, replit.nix, poetry/requirements/package.json, etc.

3. Configuration & Secrets
List all environment variables referenced in code (search for os.getenv, process.env, config readers)

Identify which are required at runtime vs. optional

Note any .env, .env.example, or secrets templates

Flag missing/undefined but referenced vars

4. Dependencies & Tooling
Enumerate dependencies with versions (requirements.txt/pyproject.toml or package.json/lockfile)

Highlight deprecated, vulnerable, or pinned-to-old versions likely to break soon

Note process managers (Gunicorn, supervisor), task queues (RQ/Celery/Bull), schedulers (APScheduler/Cron), and HTTP clients (requests/axios)

5. Runtime & Process Model
How the app starts (commands, ports, workers/threads)

Concurrency model (sync/async, worker counts, thread pools)

Any dev vs prod switches (feature flags, conditionals)

6. HTTP Endpoints & Webhooks
List all routes with methods and purpose (e.g., /webhook, /health, /ops)

For each webhook: expected headers, signature verification, idempotency/dedupe, response timings

Identify Graph API or WhatsApp Cloud API usage if present

7. Background Jobs, Queues, and Schedules
Identify queue technology (Redis/RQ/Celery/etc.), queue names, and workers

Leader-election or single-worker locks (if any)

APScheduler/Cron tasks and their intervals

8. Database & Storage
Database type(s) and client libraries

Connection strings and pooling configs

Migrations presence

High-level schema summary: key tables/collections and their purpose

Object storage/buckets if referenced

9. Feature Flags & Safe Switches
List all flags (e.g., OUTBOUND_ENABLED, OUTBOUND_VIA_MAKE, ENV, whitelists)

Default values, where set, and behavior they control

10. Observability & Ops
Health/readiness endpoints

Logging strategy and log levels

Metrics or tracing (if any)

Admin/ops panels and what they show

11. Security Posture
Input validation, auth, and signature checks

Secret handling

Common risks (hard-coded tokens, CORS, open admin routes)

PII handling if any

12. Performance & Reliability Risks
Known slow paths (e.g., sync network calls on hot webhooks)

Timeouts, retries, and backoff policies

Idempotency coverage

Places where blocking I/O can stall the request thread

13. Notable Findings (Issues & Gaps)
Concrete issues with file references

Misconfigurations and missing env vars

Anything likely to break on redeploy

Third-party integration pitfalls (Meta Graph, Make, etc.)

14. Quick Wins (Now), Next, Later
Now (0–1 day): small, high-impact, low-risk items

Next (2–7 days): meaningful improvements

Later (>7 days): structural refactors

15. UAT Checklist (for this repo)
Health endpoint returns 200 on deploy URL

Duplicate message IDs ignored

Whitelist blocks non-test PSIDs in UAT

Background worker single leader confirmed

Outbound toggles behave as expected

16. Appendices
A. Exact Start/Run Commands detected

B. Env Var Matrix (name, required?, used in files, notes)

C. Dependency Risk Table (name, version, purpose, risk)

D. Route Inventory (method, path, purpose, auth?, rate limit?)

E. File-specific notes (TODO/FIXME hotspots, dead code)

F. Integration touchpoints (Graph API, Make/n8n/Zapier): endpoints, payload shapes, headers

How to Work
Analyze statically. You may open and read files and configs.

Do not execute migrations, send outbound HTTP, or mutate state.

If something is ambiguous, infer carefully and label it “Assumption”.

Output Requirements
Create Replit_Audit_Summary.md with the sections above, fully populated.

Export a .docx twin named Replit_Audit_Summary.docx with identical content.

Place both in the project root.

At the top of the doc, include a timestamp and the branch/commit hash if available.

Acceptance Criteria
The document is complete, consistent, and maps every claim to real files or code locations.

All feature flags, endpoints, and env vars referenced in code are captured.

Risks and quick wins are prioritized and actionable.

No files were modified beyond creating the two audit documents.

When finished, reply with:

A short confirmation message

The relative paths of the two created files

