AGENT PROMPT — Phase B (Cloudflare R2 / S3-compatible)

You are my senior production engineer. Migrate file handling to **Cloudflare R2** (S3-compatible) with signed URLs only, non-breaking. Reuse utils/logger.py. Keep init order.

Provider: R2 (S3 API)
Env vars (I will set secrets):
R2_ENDPOINT, R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY, R2_BUCKET=user-assets, R2_REGION=auto (if needed)

Goals
1) Server endpoints:
   - POST /assets/upload-url  ({"path","content_type","size"}) → {"upload_url","expires_in":60,"path"}
   - GET /assets/download-url?path=... → {"download_url","expires_in":60}
   - Optional DELETE /assets?path=... if ASSETS_ALLOW_DELETE=true
2) Security/validation identical to Supabase version:
   - Require X-User-ID, enforce path prefix "{user_id}/", content-type allowlist, size ≤10MB.
3) Use boto3 S3 client with signature v4 to mint presigned URLs (PUT for upload, GET for download). Expiry 60s.
4) Logging: use utils/logger.py; include request_id, user_id, path, op, status, latency_ms.
5) Tests: pytest; mock boto3 client.
6) Docs + acceptance; migration helper to push local files to R2.

Changes (additive)
A) Create app/storage_r2.py
   - s3_client = boto3.client("s3", endpoint_url=R2_ENDPOINT, aws_access_key_id=..., aws_secret_access_key=..., region_name=R2_REGION)
   - get_presigned_put(path, content_type, expires=60)
   - get_presigned_get(path, expires=60)
   - delete_object(path)

B) Create app/routes_assets.py (same contract as Supabase version, shared validations).

C) Wire blueprint in app.py without disturbing existing logic.

D) requirements.txt: ensure/pin boto3>=1.34, pytest>=8.0, moto[s3]>=5.0 for tests.

E) tests/test_assets_r2.py
   - Patch boto3 client to return deterministic presigned URLs
   - Validate security checks & happy path

F) /docs/storage-spec.md and /docs/storage-acceptance.md
   (Same content as Supabase version, but note “Provider: Cloudflare R2 (S3 presign)” and mention PUT/GET presigning with 60s expiry.)

G) tools/migrate_assets_r2.py
   - CLI: python tools/migrate_assets_r2.py --src ./local_uploads --user-id <uid>
   - Upload each file to R2 via put_object; set content-type; log JSON per file.

Output & verify
- Install deps; run pytest -q (show passing).
- Start server and demonstrate POST /assets/upload-url and GET /assets/download-url.
- Show successful upload (curl -X PUT ...) and download (curl), both within expiry.
- Commit: feat(storage): R2 signed URLs, secure endpoints, tests, docs, migration helper
