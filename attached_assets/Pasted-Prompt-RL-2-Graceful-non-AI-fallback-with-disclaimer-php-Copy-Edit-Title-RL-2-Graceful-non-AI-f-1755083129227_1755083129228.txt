Prompt RL-2 ‚Äî Graceful non-AI fallback with disclaimer
php
Copy
Edit
Title: RL-2 ‚Äî Graceful non-AI fallback with disclaimer

Goal:
When the AI limiter trips, the worker must return a fast, deterministic response (rules/regex), append a short disclaimer, and finalize the job without re-enqueueing. No rich templates; plain text only.

Behavior:
1) If ai_rate_limited=true for this job:
   - Try deterministic rules first:
     ‚Ä¢ Expense log: "log <amount> <note>" or "spent <amount> <note>" or "<amount> <note>"
     ‚Ä¢ Show help if no pattern matched.
   - Reply (<=280 chars), exactly:
     "üòÆ‚Äçüí® Taking a quick breather. I can do 2 smart replies/min per person.
      ‚úÖ I handled that without AI this time.
      Tip: you can always type summary for a quick recap."
   - Do not requeue. Mark job_status='done' and ai_reason='per_psid_limit'|'global_limit'.

2) If user sent "summary" while limited:
   - Compute deterministic summary (no AI): totals today, 7d, 30d; top 3 categories.
   - Prepend exactly:
     "üòÆ‚Äçüí® Quick note: smart replies are capped at 2/min. Here‚Äôs your recap without AI:"
   - Do not requeue. Mark job_status='done', ai_reason as above.

3) Skip all rich UI. Plain text only.

4) Logging for each job:
   { rid, psid_hash, ai_allowed:boolean, reason:"ok|per_psid_limit|global_limit",
     tokens_remaining:int|null, window_reset_at:ts, handled_by:"ai|rules", job_status:"done|failed" }

5) Absolutely prevent loops:
   - Each job gets idempotency_key = rid. Enforce unique constraint in job_log.
   - ack the queue message only after DB commit succeeds.
   - If deterministic handler runs, DO NOT re-enqueue; set next_action=null.

6) Performance guardrails:
   - End-to-end budget: ‚â§100ms. Timebox regex parse to 10ms. Summaries use pre-aggregated views or single SELECTs with LIMIT.

Acceptance:
- When rate-limited, user always gets a valid rules/summary reply with the disclaimer.
- No repeat deliveries or reprocessing for the same rid.
- expenses table and job_log reflect the operation within the same transaction.
Worker reference (Python-ish pseudocode)
python
Copy
Edit
def handle_job(job):
    rid = job["rid"]
    with db.transaction() as tx:
        if already_processed(rid, tx):
            ack(job); return

        rl = check_rate_limits(job["psid"])
        ai_allowed = not rl.limited
        reason = rl.reason or "ok"

        if not ai_allowed:
            handled, text = handle_deterministic(job)
            if not handled:
                text = (
                    "üòÆ‚Äçüí® Taking a quick breather. I can do 2 smart replies/min per person.\n"
                    "‚úÖ I handled that without AI this time.\n"
                    "Tip: you can always type summary for a quick recap.\n"
                    "Try: log 250 lunch"
                )
            send_plaintext(job["channel"], job["recipient"], text)

            log_job(tx, rid, job["psid_hash"], ai_allowed=False,
                    reason=reason, handled_by="rules", status="done")

            tx.commit()     # commit before ack to ensure persistence
            ack(job)        # NEVER requeue on RL path
            return

        # AI path (not shown here)
        # ...

def handle_deterministic(job):
    text = normalize(job["message"])

    # 1) Summary
    if text.strip() == "summary":
        summary = compute_summary(job["user_id"])
        out = (
          "üòÆ‚Äçüí® Quick note: smart replies are capped at 2/min. Here‚Äôs your recap without AI:\n"
          f"{summary}"
        )
        return True, out

    # 2) Logging
    m = match_expense(text)  # regex helper below
    if m:
        amount, note, category = m.amount, m.note, infer_category(note)
        insert_expense(job["user_id"], amount, note, category)  # single INSERT
        out = (
          "üòÆ‚Äçüí® Taking a quick breather. I can do 2 smart replies/min per person.\n"
          "‚úÖ I handled that without AI this time.\n"
          f"Logged: {amount} ‚Äì {note} [{category}]"
        )
        return True, out

    # 3) Help
    out = (
      "üòÆ‚Äçüí® Taking a quick breather. I can do 2 smart replies/min per person.\n"
      "‚úÖ I handled that without AI this time.\n"
      "Tip: you can always type summary for a quick recap.\n"
      "Try: log 250 lunch"
    )
    return False, out
Regex helpers (fast + forgiving)
python
Copy
Edit
LOG_PATTERNS = [
    r"^(?:log|spent|add)\s+(\d+(?:\.\d{1,2})?)\s+(.+)$",
    r"^(\d+(?:\.\d{1,2})?)\s+(.+)$",
]
# e.g. "log 250 lunch", "spent 120 taxi gulshan", "300 groceries"
Deterministic summary (single-query style)
Today total

Last 7 days total

Last 30 days total

Top 3 categories (30d)

SQL sketch (Postgres):

sql
Copy
Edit
-- today, 7d, 30d in one call
WITH
  t AS (
    SELECT
      SUM(amount) FILTER (WHERE created_at::date = CURRENT_DATE) AS today,
      SUM(amount) FILTER (WHERE created_at >= CURRENT_DATE - INTERVAL '7 days') AS d7,
      SUM(amount) FILTER (WHERE created_at >= CURRENT_DATE - INTERVAL '30 days') AS d30
    FROM expenses
    WHERE user_id = $1
  ),
  top AS (
    SELECT category, SUM(amount) AS total
    FROM expenses
    WHERE user_id = $1
      AND created_at >= CURRENT_DATE - INTERVAL '30 days'
    GROUP BY category
    ORDER BY total DESC
    LIMIT 3
  )
SELECT
  t.today, t.d7, t.d30,
  COALESCE(json_agg(top ORDER BY top.total DESC), '[]'::json) AS top3
FROM t, (SELECT * FROM top) top;
Format reply like:

yaml
Copy
Edit
Today: BDT 1,250 | 7d: 9,430 | 30d: 27,180
Top: groceries 9,000 ‚Ä¢ transport 5,200 ‚Ä¢ eating_out 3,100
DB migrations (to support RL-2 & idempotency)
sql
Copy
Edit
-- Ensure expenses writes are visible immediately
ALTER TABLE expenses
  ALTER COLUMN created_at SET DEFAULT NOW();

-- Job log (if you don‚Äôt have one yet)
CREATE TABLE IF NOT EXISTS job_log (
  rid TEXT PRIMARY KEY,
  psid_hash TEXT NOT NULL,
  ai_allowed BOOLEAN NOT NULL,
  reason TEXT NOT NULL,          -- "ok" | "per_psid_limit" | "global_limit"
  handled_by TEXT NOT NULL,      -- "ai" | "rules"
  tokens_remaining INT,
  window_reset_at TIMESTAMPTZ,
  job_status TEXT NOT NULL,      -- "done" | "failed"
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Optional: index for analytics
CREATE INDEX IF NOT EXISTS job_log_created_at_idx ON job_log(created_at DESC);
Why this matters: rid is the idempotency key. If the worker accidentally re-sees the same job, the insert will fail; you treat it as already processed and ack without doing anything‚Äîno duplicate expense rows, no loops.

Fixing your ‚Äústuck in a loop‚Äù + ‚Äútable not updating‚Äù
Here are the most common culprits and the exact fixes:

Job re-enqueues itself when rate-limited
Symptom: Same rid shows up repeatedly; user gets repeated disclaimer; no DB rows.
Fixes:

Ensure RL path never sets next_action or requeue=True.

After sending the fallback text, commit DB, then ack the message. No requeue.

DB transaction never commits on deterministic path
Symptom: Logs show ‚Äúsent reply‚Äù, but expenses/job_log don‚Äôt change.
Fixes:

Wrap deterministic handling in a transaction and call COMMIT before ack.

If using SQLAlchemy, call session.commit() and then ack.

Turn on autocommit only if you‚Äôre not managing transactions explicitly.

Idempotency missing
Symptom: Duplicate expense lines or repeated processing on retries; sometimes rejected by unique keys in other tables causing rollbacks.
Fix: Insert into job_log with rid as PK first; if conflict, short-circuit and ack. Or INSERT ... ON CONFLICT DO NOTHING + check rowcount.

Multiple consumers processing the same message
Symptom: Race conditions, rollbacks, or ‚Äústuck‚Äù feeling.
Fixes:

Ensure only one worker/queue consumer for the same partition/shard.

Use visibility timeouts / exclusive locks correctly (depends on your queue).

Rate-limit check sets ai_rate_limited=true and then re-checks in a tight loop
Symptom: Hot loop churning CPU; no writes.
Fix: On RL hit, exit processing path after deterministic reply; don‚Äôt loop until window reset. Optionally add a small sleep/backoff if you must re-poll (but better to exit entirely).

Connection pool exhaustion
Symptom: Worker logs show timeouts on DB; no updates.
Fix: Keep deterministic path short; reuse pooled connections; ensure you close cursors; set pool size = worker concurrency.

Unhandled exception after sending message
Symptom: User sees reply but DB never updated because the exception rolled back.
Fix: Catch exceptions around post-send logging; log first, then send, or send then separately log in a try/except that never raises.

Drop-in tests (quick sanity)
Deterministic log path:
Send: log 250 lunch three times within a minute.
Expect: First two go AI or rules depending on limit; third must be rules with disclaimer; exactly 3 rows in expenses, 3 rows in job_log.

Idempotency:
Re-deliver same rid (simulate queue redelivery).
Expect: Worker acks without any new DB writes.

Summary while limited:
Send: summary after hitting 2/min.
Expect: Deterministic recap with the ‚ÄúQuick note‚Äù line; no AI invocation.

One-line hotfix you can add right now (prevents loops)
python
Copy
Edit
if rl.limited:
    handled, text = handle_deterministic(job)
    send_plaintext(job["channel"], job["recipient"], text)
    try:
        db.insert_job_log(rid=rid, psid_hash=job["psid_hash"], ai_allowed=False,
                          reason=rl.reason, handled_by="rules", job_status="done")
        db.commit()
    finally:
        ack(job)  # NEVER requeue on RL path
    return